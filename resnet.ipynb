{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS NOTEBOOK IS NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_height = 48\n",
    "img_width = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = tf.keras.applications.ResNet101V2(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    pooling='avg',\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resnet101.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir_train = pathlib.Path('./images/images/train')\n",
    "data_dir_val = pathlib.Path('./images/images/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data as RGB just to match the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  label_mode='categorical',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_val,\n",
    "  image_size=(img_height, img_width),\n",
    "  label_mode='categorical',\n",
    "  batch_size=batch_size,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "\n",
    "def custom_preprocess_input(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_ds = train_ds.map(custom_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_ds = val_ds.map(custom_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import RandomFlip, RandomRotation, Rescaling, RandomZoom\n",
    "\n",
    "# rescaling = Sequential([\n",
    "#     Rescaling(1./127.5, offset=-1),\n",
    "# ])\n",
    "\n",
    "# preprocessing_seq = Sequential([\n",
    "#     rescaling,\n",
    "#     RandomFlip(),\n",
    "#     RandomRotation(0.2),\n",
    "#     RandomZoom(\n",
    "#         height_factor=(-0.2, 0.2),\n",
    "#         width_factor=(-0.2, 0.2)\n",
    "#     )\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train_ds = train_ds.map(\n",
    "#     lambda x, y: (preprocessing_seq(x, training=True), y)\n",
    "# )\n",
    "\n",
    "# new_val_ds = val_ds.map(\n",
    "#     lambda x, y: (rescaling(x), y)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "repurposed = Sequential([\n",
    "    resnet101, \n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet101.layers[:341]:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "\n",
    "repurposed.compile(optimizer=Adam(learning_rate=0.01), loss=categorical_crossentropy, metrics=['accuracy', AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repurposed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet101.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 624ms/step - accuracy: 0.2627 - auc: 0.6596 - loss: 1.8559 - val_accuracy: 0.3869 - val_auc: 0.7683 - val_loss: 1.5784 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 628ms/step - accuracy: 0.3613 - auc: 0.7518 - loss: 1.6272 - val_accuracy: 0.4340 - val_auc: 0.8048 - val_loss: 1.4745 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 609ms/step - accuracy: 0.4002 - auc: 0.7778 - loss: 1.5597 - val_accuracy: 0.4370 - val_auc: 0.8036 - val_loss: 1.4873 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 622ms/step - accuracy: 0.4170 - auc: 0.7906 - loss: 1.5218 - val_accuracy: 0.3955 - val_auc: 0.7872 - val_loss: 1.5700 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 605ms/step - accuracy: 0.4348 - auc: 0.8023 - loss: 1.4873 - val_accuracy: 0.4733 - val_auc: 0.8213 - val_loss: 1.4117 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 638ms/step - accuracy: 0.4476 - auc: 0.8137 - loss: 1.4508 - val_accuracy: 0.4767 - val_auc: 0.8276 - val_loss: 1.4008 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 612ms/step - accuracy: 0.4678 - auc: 0.8245 - loss: 1.4127 - val_accuracy: 0.4600 - val_auc: 0.8262 - val_loss: 1.4220 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 616ms/step - accuracy: 0.4776 - auc: 0.8278 - loss: 1.4019 - val_accuracy: 0.5118 - val_auc: 0.8441 - val_loss: 1.3402 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 613ms/step - accuracy: 0.4796 - auc: 0.8321 - loss: 1.3865 - val_accuracy: 0.5453 - val_auc: 0.8727 - val_loss: 1.2315 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 610ms/step - accuracy: 0.4996 - auc: 0.8389 - loss: 1.3607 - val_accuracy: 0.5621 - val_auc: 0.8756 - val_loss: 1.2339 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 619ms/step - accuracy: 0.5045 - auc: 0.8435 - loss: 1.3447 - val_accuracy: 0.5709 - val_auc: 0.8809 - val_loss: 1.1909 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 610ms/step - accuracy: 0.5134 - auc: 0.8468 - loss: 1.3312 - val_accuracy: 0.5856 - val_auc: 0.8889 - val_loss: 1.1685 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 629ms/step - accuracy: 0.5235 - auc: 0.8539 - loss: 1.3028 - val_accuracy: 0.5870 - val_auc: 0.8905 - val_loss: 1.1762 - learning_rate: 0.0100\n",
      "Epoch 14/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 615ms/step - accuracy: 0.5350 - auc: 0.8592 - loss: 1.2800 - val_accuracy: 0.6039 - val_auc: 0.8965 - val_loss: 1.1363 - learning_rate: 0.0100\n",
      "Epoch 15/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 621ms/step - accuracy: 0.5492 - auc: 0.8684 - loss: 1.2427 - val_accuracy: 0.6276 - val_auc: 0.9080 - val_loss: 1.1017 - learning_rate: 0.0100\n",
      "Epoch 16/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 619ms/step - accuracy: 0.5649 - auc: 0.8744 - loss: 1.2143 - val_accuracy: 0.6501 - val_auc: 0.9155 - val_loss: 1.1077 - learning_rate: 0.0100\n",
      "Epoch 17/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 623ms/step - accuracy: 0.5549 - auc: 0.8709 - loss: 1.2285 - val_accuracy: 0.6197 - val_auc: 0.9058 - val_loss: 1.1620 - learning_rate: 0.0100\n",
      "Epoch 18/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 611ms/step - accuracy: 0.5614 - auc: 0.8754 - loss: 1.2111 - val_accuracy: 0.6352 - val_auc: 0.9094 - val_loss: 1.1485 - learning_rate: 0.0100\n",
      "Epoch 19/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.5584 - auc: 0.8705 - loss: 1.2319\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 642ms/step - accuracy: 0.5584 - auc: 0.8706 - loss: 1.2318 - val_accuracy: 0.5949 - val_auc: 0.8955 - val_loss: 1.1838 - learning_rate: 0.0100\n",
      "Epoch 20/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 627ms/step - accuracy: 0.5894 - auc: 0.8880 - loss: 1.1476 - val_accuracy: 0.6856 - val_auc: 0.9301 - val_loss: 0.9577 - learning_rate: 0.0050\n",
      "Epoch 21/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 646ms/step - accuracy: 0.6170 - auc: 0.9013 - loss: 1.0801 - val_accuracy: 0.7189 - val_auc: 0.9430 - val_loss: 0.9311 - learning_rate: 0.0050\n",
      "Epoch 22/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 667ms/step - accuracy: 0.6319 - auc: 0.9076 - loss: 1.0442 - val_accuracy: 0.7010 - val_auc: 0.9368 - val_loss: 0.9901 - learning_rate: 0.0050\n",
      "Epoch 23/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 622ms/step - accuracy: 0.6432 - auc: 0.9124 - loss: 1.0188 - val_accuracy: 0.7273 - val_auc: 0.9478 - val_loss: 0.9881 - learning_rate: 0.0050\n",
      "Epoch 24/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 622ms/step - accuracy: 0.6459 - auc: 0.9156 - loss: 0.9992 - val_accuracy: 0.7261 - val_auc: 0.9470 - val_loss: 1.0304 - learning_rate: 0.0050\n",
      "Epoch 25/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.6537 - auc: 0.9180 - loss: 0.9852\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 620ms/step - accuracy: 0.6537 - auc: 0.9180 - loss: 0.9851 - val_accuracy: 0.7580 - val_auc: 0.9565 - val_loss: 0.9667 - learning_rate: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 626ms/step - accuracy: 0.6693 - auc: 0.9253 - loss: 0.9407 - val_accuracy: 0.7907 - val_auc: 0.9655 - val_loss: 0.9502 - learning_rate: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 623ms/step - accuracy: 0.6812 - auc: 0.9285 - loss: 0.9193 - val_accuracy: 0.7970 - val_auc: 0.9678 - val_loss: 0.9568 - learning_rate: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 614ms/step - accuracy: 0.6897 - auc: 0.9336 - loss: 0.8853 - val_accuracy: 0.8038 - val_auc: 0.9686 - val_loss: 0.9224 - learning_rate: 0.0025\n",
      "Epoch 29/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 612ms/step - accuracy: 0.6931 - auc: 0.9348 - loss: 0.8802 - val_accuracy: 0.7981 - val_auc: 0.9688 - val_loss: 0.9813 - learning_rate: 0.0025\n",
      "Epoch 30/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 613ms/step - accuracy: 0.7011 - auc: 0.9371 - loss: 0.8615 - val_accuracy: 0.8154 - val_auc: 0.9720 - val_loss: 0.9889 - learning_rate: 0.0025\n",
      "Epoch 31/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 610ms/step - accuracy: 0.7059 - auc: 0.9397 - loss: 0.8438 - val_accuracy: 0.8226 - val_auc: 0.9737 - val_loss: 1.0144 - learning_rate: 0.0025\n",
      "Epoch 32/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7156 - auc: 0.9417 - loss: 0.8289\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 620ms/step - accuracy: 0.7157 - auc: 0.9417 - loss: 0.8288 - val_accuracy: 0.8296 - val_auc: 0.9752 - val_loss: 1.0169 - learning_rate: 0.0025\n",
      "Epoch 33/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 622ms/step - accuracy: 0.7213 - auc: 0.9443 - loss: 0.8086 - val_accuracy: 0.8343 - val_auc: 0.9764 - val_loss: 0.9847 - learning_rate: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 622ms/step - accuracy: 0.7244 - auc: 0.9458 - loss: 0.7969 - val_accuracy: 0.8372 - val_auc: 0.9775 - val_loss: 1.0153 - learning_rate: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 627ms/step - accuracy: 0.7279 - auc: 0.9472 - loss: 0.7859 - val_accuracy: 0.8422 - val_auc: 0.9785 - val_loss: 0.9831 - learning_rate: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.7341 - auc: 0.9480 - loss: 0.7797\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 619ms/step - accuracy: 0.7342 - auc: 0.9480 - loss: 0.7795 - val_accuracy: 0.8389 - val_auc: 0.9782 - val_loss: 0.9591 - learning_rate: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 632ms/step - accuracy: 0.7329 - auc: 0.9496 - loss: 0.7687 - val_accuracy: 0.8478 - val_auc: 0.9791 - val_loss: 1.0124 - learning_rate: 6.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 628ms/step - accuracy: 0.7462 - auc: 0.9524 - loss: 0.7457 - val_accuracy: 0.8543 - val_auc: 0.9806 - val_loss: 0.9594 - learning_rate: 6.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 630ms/step - accuracy: 0.7439 - auc: 0.9519 - loss: 0.7505 - val_accuracy: 0.8559 - val_auc: 0.9810 - val_loss: 0.9241 - learning_rate: 6.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.7448 - auc: 0.9538 - loss: 0.7356\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 629ms/step - accuracy: 0.7449 - auc: 0.9538 - loss: 0.7355 - val_accuracy: 0.8578 - val_auc: 0.9812 - val_loss: 0.9436 - learning_rate: 6.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 633ms/step - accuracy: 0.7506 - auc: 0.9549 - loss: 0.7247 - val_accuracy: 0.8573 - val_auc: 0.9810 - val_loss: 0.9770 - learning_rate: 3.1250e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 629ms/step - accuracy: 0.7478 - auc: 0.9537 - loss: 0.7346 - val_accuracy: 0.8611 - val_auc: 0.9817 - val_loss: 0.9705 - learning_rate: 3.1250e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 628ms/step - accuracy: 0.7549 - auc: 0.9552 - loss: 0.7233 - val_accuracy: 0.8605 - val_auc: 0.9817 - val_loss: 0.9834 - learning_rate: 3.1250e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.7522 - auc: 0.9552 - loss: 0.7231\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 624ms/step - accuracy: 0.7523 - auc: 0.9552 - loss: 0.7230 - val_accuracy: 0.8614 - val_auc: 0.9818 - val_loss: 0.9354 - learning_rate: 3.1250e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 624ms/step - accuracy: 0.7528 - auc: 0.9543 - loss: 0.7308 - val_accuracy: 0.8625 - val_auc: 0.9819 - val_loss: 1.0105 - learning_rate: 1.5625e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 627ms/step - accuracy: 0.7550 - auc: 0.9540 - loss: 0.7305 - val_accuracy: 0.8613 - val_auc: 0.9816 - val_loss: 0.9902 - learning_rate: 1.5625e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 629ms/step - accuracy: 0.7574 - auc: 0.9564 - loss: 0.7133 - val_accuracy: 0.8633 - val_auc: 0.9822 - val_loss: 0.9458 - learning_rate: 1.5625e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.7532 - auc: 0.9558 - loss: 0.7175\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 632ms/step - accuracy: 0.7532 - auc: 0.9558 - loss: 0.7174 - val_accuracy: 0.8636 - val_auc: 0.9823 - val_loss: 0.9267 - learning_rate: 1.5625e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 633ms/step - accuracy: 0.7500 - auc: 0.9540 - loss: 0.7296 - val_accuracy: 0.8649 - val_auc: 0.9823 - val_loss: 0.9135 - learning_rate: 7.8125e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 639ms/step - accuracy: 0.7527 - auc: 0.9563 - loss: 0.7132 - val_accuracy: 0.8652 - val_auc: 0.9822 - val_loss: 0.9549 - learning_rate: 7.8125e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23b81736a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor = 'val_loss', patience = 4, verbose = 1, factor = 0.50, min_lr = 1e-6)\n",
    "\n",
    "repurposed.fit(new_train_ds, validation_data=new_val_ds, epochs=epochs, callbacks=[reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "repurposed.save('resnetfinedtuned.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tuning = 274\n",
    "\n",
    "for layer in resnet101.layers[start_tuning:]:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer - False\n",
      "1 conv1_pad - False\n",
      "2 conv1_conv - False\n",
      "3 pool1_pad - False\n",
      "4 pool1_pool - False\n",
      "5 conv2_block1_preact_bn - False\n",
      "6 conv2_block1_preact_relu - False\n",
      "7 conv2_block1_1_conv - False\n",
      "8 conv2_block1_1_bn - False\n",
      "9 conv2_block1_1_relu - False\n",
      "10 conv2_block1_2_pad - False\n",
      "11 conv2_block1_2_conv - False\n",
      "12 conv2_block1_2_bn - False\n",
      "13 conv2_block1_2_relu - False\n",
      "14 conv2_block1_0_conv - False\n",
      "15 conv2_block1_3_conv - False\n",
      "16 conv2_block1_out - False\n",
      "17 conv2_block2_preact_bn - False\n",
      "18 conv2_block2_preact_relu - False\n",
      "19 conv2_block2_1_conv - False\n",
      "20 conv2_block2_1_bn - False\n",
      "21 conv2_block2_1_relu - False\n",
      "22 conv2_block2_2_pad - False\n",
      "23 conv2_block2_2_conv - False\n",
      "24 conv2_block2_2_bn - False\n",
      "25 conv2_block2_2_relu - False\n",
      "26 conv2_block2_3_conv - False\n",
      "27 conv2_block2_out - False\n",
      "28 conv2_block3_preact_bn - False\n",
      "29 conv2_block3_preact_relu - False\n",
      "30 conv2_block3_1_conv - False\n",
      "31 conv2_block3_1_bn - False\n",
      "32 conv2_block3_1_relu - False\n",
      "33 conv2_block3_2_pad - False\n",
      "34 conv2_block3_2_conv - False\n",
      "35 conv2_block3_2_bn - False\n",
      "36 conv2_block3_2_relu - False\n",
      "37 max_pooling2d - False\n",
      "38 conv2_block3_3_conv - False\n",
      "39 conv2_block3_out - False\n",
      "40 conv3_block1_preact_bn - False\n",
      "41 conv3_block1_preact_relu - False\n",
      "42 conv3_block1_1_conv - False\n",
      "43 conv3_block1_1_bn - False\n",
      "44 conv3_block1_1_relu - False\n",
      "45 conv3_block1_2_pad - False\n",
      "46 conv3_block1_2_conv - False\n",
      "47 conv3_block1_2_bn - False\n",
      "48 conv3_block1_2_relu - False\n",
      "49 conv3_block1_0_conv - False\n",
      "50 conv3_block1_3_conv - False\n",
      "51 conv3_block1_out - False\n",
      "52 conv3_block2_preact_bn - False\n",
      "53 conv3_block2_preact_relu - False\n",
      "54 conv3_block2_1_conv - False\n",
      "55 conv3_block2_1_bn - False\n",
      "56 conv3_block2_1_relu - False\n",
      "57 conv3_block2_2_pad - False\n",
      "58 conv3_block2_2_conv - False\n",
      "59 conv3_block2_2_bn - False\n",
      "60 conv3_block2_2_relu - False\n",
      "61 conv3_block2_3_conv - False\n",
      "62 conv3_block2_out - False\n",
      "63 conv3_block3_preact_bn - False\n",
      "64 conv3_block3_preact_relu - False\n",
      "65 conv3_block3_1_conv - False\n",
      "66 conv3_block3_1_bn - False\n",
      "67 conv3_block3_1_relu - False\n",
      "68 conv3_block3_2_pad - False\n",
      "69 conv3_block3_2_conv - False\n",
      "70 conv3_block3_2_bn - False\n",
      "71 conv3_block3_2_relu - False\n",
      "72 conv3_block3_3_conv - False\n",
      "73 conv3_block3_out - False\n",
      "74 conv3_block4_preact_bn - False\n",
      "75 conv3_block4_preact_relu - False\n",
      "76 conv3_block4_1_conv - False\n",
      "77 conv3_block4_1_bn - False\n",
      "78 conv3_block4_1_relu - False\n",
      "79 conv3_block4_2_pad - False\n",
      "80 conv3_block4_2_conv - False\n",
      "81 conv3_block4_2_bn - False\n",
      "82 conv3_block4_2_relu - False\n",
      "83 max_pooling2d_1 - False\n",
      "84 conv3_block4_3_conv - False\n",
      "85 conv3_block4_out - False\n",
      "86 conv4_block1_preact_bn - False\n",
      "87 conv4_block1_preact_relu - False\n",
      "88 conv4_block1_1_conv - False\n",
      "89 conv4_block1_1_bn - False\n",
      "90 conv4_block1_1_relu - False\n",
      "91 conv4_block1_2_pad - False\n",
      "92 conv4_block1_2_conv - False\n",
      "93 conv4_block1_2_bn - False\n",
      "94 conv4_block1_2_relu - False\n",
      "95 conv4_block1_0_conv - False\n",
      "96 conv4_block1_3_conv - False\n",
      "97 conv4_block1_out - False\n",
      "98 conv4_block2_preact_bn - False\n",
      "99 conv4_block2_preact_relu - False\n",
      "100 conv4_block2_1_conv - False\n",
      "101 conv4_block2_1_bn - False\n",
      "102 conv4_block2_1_relu - False\n",
      "103 conv4_block2_2_pad - False\n",
      "104 conv4_block2_2_conv - False\n",
      "105 conv4_block2_2_bn - False\n",
      "106 conv4_block2_2_relu - False\n",
      "107 conv4_block2_3_conv - False\n",
      "108 conv4_block2_out - False\n",
      "109 conv4_block3_preact_bn - False\n",
      "110 conv4_block3_preact_relu - False\n",
      "111 conv4_block3_1_conv - False\n",
      "112 conv4_block3_1_bn - False\n",
      "113 conv4_block3_1_relu - False\n",
      "114 conv4_block3_2_pad - False\n",
      "115 conv4_block3_2_conv - False\n",
      "116 conv4_block3_2_bn - False\n",
      "117 conv4_block3_2_relu - False\n",
      "118 conv4_block3_3_conv - False\n",
      "119 conv4_block3_out - False\n",
      "120 conv4_block4_preact_bn - False\n",
      "121 conv4_block4_preact_relu - False\n",
      "122 conv4_block4_1_conv - False\n",
      "123 conv4_block4_1_bn - False\n",
      "124 conv4_block4_1_relu - False\n",
      "125 conv4_block4_2_pad - False\n",
      "126 conv4_block4_2_conv - False\n",
      "127 conv4_block4_2_bn - False\n",
      "128 conv4_block4_2_relu - False\n",
      "129 conv4_block4_3_conv - False\n",
      "130 conv4_block4_out - False\n",
      "131 conv4_block5_preact_bn - False\n",
      "132 conv4_block5_preact_relu - False\n",
      "133 conv4_block5_1_conv - False\n",
      "134 conv4_block5_1_bn - False\n",
      "135 conv4_block5_1_relu - False\n",
      "136 conv4_block5_2_pad - False\n",
      "137 conv4_block5_2_conv - False\n",
      "138 conv4_block5_2_bn - False\n",
      "139 conv4_block5_2_relu - False\n",
      "140 conv4_block5_3_conv - False\n",
      "141 conv4_block5_out - False\n",
      "142 conv4_block6_preact_bn - False\n",
      "143 conv4_block6_preact_relu - False\n",
      "144 conv4_block6_1_conv - False\n",
      "145 conv4_block6_1_bn - False\n",
      "146 conv4_block6_1_relu - False\n",
      "147 conv4_block6_2_pad - False\n",
      "148 conv4_block6_2_conv - False\n",
      "149 conv4_block6_2_bn - False\n",
      "150 conv4_block6_2_relu - False\n",
      "151 conv4_block6_3_conv - False\n",
      "152 conv4_block6_out - False\n",
      "153 conv4_block7_preact_bn - False\n",
      "154 conv4_block7_preact_relu - False\n",
      "155 conv4_block7_1_conv - False\n",
      "156 conv4_block7_1_bn - False\n",
      "157 conv4_block7_1_relu - False\n",
      "158 conv4_block7_2_pad - False\n",
      "159 conv4_block7_2_conv - False\n",
      "160 conv4_block7_2_bn - False\n",
      "161 conv4_block7_2_relu - False\n",
      "162 conv4_block7_3_conv - False\n",
      "163 conv4_block7_out - False\n",
      "164 conv4_block8_preact_bn - False\n",
      "165 conv4_block8_preact_relu - False\n",
      "166 conv4_block8_1_conv - False\n",
      "167 conv4_block8_1_bn - False\n",
      "168 conv4_block8_1_relu - False\n",
      "169 conv4_block8_2_pad - False\n",
      "170 conv4_block8_2_conv - False\n",
      "171 conv4_block8_2_bn - False\n",
      "172 conv4_block8_2_relu - False\n",
      "173 conv4_block8_3_conv - False\n",
      "174 conv4_block8_out - False\n",
      "175 conv4_block9_preact_bn - False\n",
      "176 conv4_block9_preact_relu - False\n",
      "177 conv4_block9_1_conv - False\n",
      "178 conv4_block9_1_bn - False\n",
      "179 conv4_block9_1_relu - False\n",
      "180 conv4_block9_2_pad - False\n",
      "181 conv4_block9_2_conv - False\n",
      "182 conv4_block9_2_bn - False\n",
      "183 conv4_block9_2_relu - False\n",
      "184 conv4_block9_3_conv - False\n",
      "185 conv4_block9_out - False\n",
      "186 conv4_block10_preact_bn - False\n",
      "187 conv4_block10_preact_relu - False\n",
      "188 conv4_block10_1_conv - False\n",
      "189 conv4_block10_1_bn - False\n",
      "190 conv4_block10_1_relu - False\n",
      "191 conv4_block10_2_pad - False\n",
      "192 conv4_block10_2_conv - False\n",
      "193 conv4_block10_2_bn - False\n",
      "194 conv4_block10_2_relu - False\n",
      "195 conv4_block10_3_conv - False\n",
      "196 conv4_block10_out - False\n",
      "197 conv4_block11_preact_bn - False\n",
      "198 conv4_block11_preact_relu - False\n",
      "199 conv4_block11_1_conv - False\n",
      "200 conv4_block11_1_bn - False\n",
      "201 conv4_block11_1_relu - False\n",
      "202 conv4_block11_2_pad - False\n",
      "203 conv4_block11_2_conv - False\n",
      "204 conv4_block11_2_bn - False\n",
      "205 conv4_block11_2_relu - False\n",
      "206 conv4_block11_3_conv - False\n",
      "207 conv4_block11_out - False\n",
      "208 conv4_block12_preact_bn - False\n",
      "209 conv4_block12_preact_relu - False\n",
      "210 conv4_block12_1_conv - False\n",
      "211 conv4_block12_1_bn - False\n",
      "212 conv4_block12_1_relu - False\n",
      "213 conv4_block12_2_pad - False\n",
      "214 conv4_block12_2_conv - False\n",
      "215 conv4_block12_2_bn - False\n",
      "216 conv4_block12_2_relu - False\n",
      "217 conv4_block12_3_conv - False\n",
      "218 conv4_block12_out - False\n",
      "219 conv4_block13_preact_bn - False\n",
      "220 conv4_block13_preact_relu - False\n",
      "221 conv4_block13_1_conv - False\n",
      "222 conv4_block13_1_bn - False\n",
      "223 conv4_block13_1_relu - False\n",
      "224 conv4_block13_2_pad - False\n",
      "225 conv4_block13_2_conv - False\n",
      "226 conv4_block13_2_bn - False\n",
      "227 conv4_block13_2_relu - False\n",
      "228 conv4_block13_3_conv - False\n",
      "229 conv4_block13_out - False\n",
      "230 conv4_block14_preact_bn - False\n",
      "231 conv4_block14_preact_relu - False\n",
      "232 conv4_block14_1_conv - False\n",
      "233 conv4_block14_1_bn - False\n",
      "234 conv4_block14_1_relu - False\n",
      "235 conv4_block14_2_pad - False\n",
      "236 conv4_block14_2_conv - False\n",
      "237 conv4_block14_2_bn - False\n",
      "238 conv4_block14_2_relu - False\n",
      "239 conv4_block14_3_conv - False\n",
      "240 conv4_block14_out - False\n",
      "241 conv4_block15_preact_bn - False\n",
      "242 conv4_block15_preact_relu - False\n",
      "243 conv4_block15_1_conv - False\n",
      "244 conv4_block15_1_bn - False\n",
      "245 conv4_block15_1_relu - False\n",
      "246 conv4_block15_2_pad - False\n",
      "247 conv4_block15_2_conv - False\n",
      "248 conv4_block15_2_bn - False\n",
      "249 conv4_block15_2_relu - False\n",
      "250 conv4_block15_3_conv - False\n",
      "251 conv4_block15_out - False\n",
      "252 conv4_block16_preact_bn - False\n",
      "253 conv4_block16_preact_relu - False\n",
      "254 conv4_block16_1_conv - False\n",
      "255 conv4_block16_1_bn - False\n",
      "256 conv4_block16_1_relu - False\n",
      "257 conv4_block16_2_pad - False\n",
      "258 conv4_block16_2_conv - False\n",
      "259 conv4_block16_2_bn - False\n",
      "260 conv4_block16_2_relu - False\n",
      "261 conv4_block16_3_conv - False\n",
      "262 conv4_block16_out - False\n",
      "263 conv4_block17_preact_bn - False\n",
      "264 conv4_block17_preact_relu - False\n",
      "265 conv4_block17_1_conv - False\n",
      "266 conv4_block17_1_bn - False\n",
      "267 conv4_block17_1_relu - False\n",
      "268 conv4_block17_2_pad - False\n",
      "269 conv4_block17_2_conv - False\n",
      "270 conv4_block17_2_bn - False\n",
      "271 conv4_block17_2_relu - False\n",
      "272 conv4_block17_3_conv - False\n",
      "273 conv4_block17_out - False\n",
      "274 conv4_block18_preact_bn - False\n",
      "275 conv4_block18_preact_relu - True\n",
      "276 conv4_block18_1_conv - True\n",
      "277 conv4_block18_1_bn - False\n",
      "278 conv4_block18_1_relu - True\n",
      "279 conv4_block18_2_pad - True\n",
      "280 conv4_block18_2_conv - True\n",
      "281 conv4_block18_2_bn - False\n",
      "282 conv4_block18_2_relu - True\n",
      "283 conv4_block18_3_conv - True\n",
      "284 conv4_block18_out - True\n",
      "285 conv4_block19_preact_bn - False\n",
      "286 conv4_block19_preact_relu - True\n",
      "287 conv4_block19_1_conv - True\n",
      "288 conv4_block19_1_bn - False\n",
      "289 conv4_block19_1_relu - True\n",
      "290 conv4_block19_2_pad - True\n",
      "291 conv4_block19_2_conv - True\n",
      "292 conv4_block19_2_bn - False\n",
      "293 conv4_block19_2_relu - True\n",
      "294 conv4_block19_3_conv - True\n",
      "295 conv4_block19_out - True\n",
      "296 conv4_block20_preact_bn - False\n",
      "297 conv4_block20_preact_relu - True\n",
      "298 conv4_block20_1_conv - True\n",
      "299 conv4_block20_1_bn - False\n",
      "300 conv4_block20_1_relu - True\n",
      "301 conv4_block20_2_pad - True\n",
      "302 conv4_block20_2_conv - True\n",
      "303 conv4_block20_2_bn - False\n",
      "304 conv4_block20_2_relu - True\n",
      "305 conv4_block20_3_conv - True\n",
      "306 conv4_block20_out - True\n",
      "307 conv4_block21_preact_bn - False\n",
      "308 conv4_block21_preact_relu - True\n",
      "309 conv4_block21_1_conv - True\n",
      "310 conv4_block21_1_bn - False\n",
      "311 conv4_block21_1_relu - True\n",
      "312 conv4_block21_2_pad - True\n",
      "313 conv4_block21_2_conv - True\n",
      "314 conv4_block21_2_bn - False\n",
      "315 conv4_block21_2_relu - True\n",
      "316 conv4_block21_3_conv - True\n",
      "317 conv4_block21_out - True\n",
      "318 conv4_block22_preact_bn - False\n",
      "319 conv4_block22_preact_relu - True\n",
      "320 conv4_block22_1_conv - True\n",
      "321 conv4_block22_1_bn - False\n",
      "322 conv4_block22_1_relu - True\n",
      "323 conv4_block22_2_pad - True\n",
      "324 conv4_block22_2_conv - True\n",
      "325 conv4_block22_2_bn - False\n",
      "326 conv4_block22_2_relu - True\n",
      "327 conv4_block22_3_conv - True\n",
      "328 conv4_block22_out - True\n",
      "329 conv4_block23_preact_bn - False\n",
      "330 conv4_block23_preact_relu - True\n",
      "331 conv4_block23_1_conv - True\n",
      "332 conv4_block23_1_bn - False\n",
      "333 conv4_block23_1_relu - True\n",
      "334 conv4_block23_2_pad - True\n",
      "335 conv4_block23_2_conv - True\n",
      "336 conv4_block23_2_bn - False\n",
      "337 conv4_block23_2_relu - True\n",
      "338 max_pooling2d_2 - True\n",
      "339 conv4_block23_3_conv - True\n",
      "340 conv4_block23_out - True\n",
      "341 conv5_block1_preact_bn - False\n",
      "342 conv5_block1_preact_relu - True\n",
      "343 conv5_block1_1_conv - True\n",
      "344 conv5_block1_1_bn - False\n",
      "345 conv5_block1_1_relu - True\n",
      "346 conv5_block1_2_pad - True\n",
      "347 conv5_block1_2_conv - True\n",
      "348 conv5_block1_2_bn - False\n",
      "349 conv5_block1_2_relu - True\n",
      "350 conv5_block1_0_conv - True\n",
      "351 conv5_block1_3_conv - True\n",
      "352 conv5_block1_out - True\n",
      "353 conv5_block2_preact_bn - False\n",
      "354 conv5_block2_preact_relu - True\n",
      "355 conv5_block2_1_conv - True\n",
      "356 conv5_block2_1_bn - False\n",
      "357 conv5_block2_1_relu - True\n",
      "358 conv5_block2_2_pad - True\n",
      "359 conv5_block2_2_conv - True\n",
      "360 conv5_block2_2_bn - False\n",
      "361 conv5_block2_2_relu - True\n",
      "362 conv5_block2_3_conv - True\n",
      "363 conv5_block2_out - True\n",
      "364 conv5_block3_preact_bn - False\n",
      "365 conv5_block3_preact_relu - True\n",
      "366 conv5_block3_1_conv - True\n",
      "367 conv5_block3_1_bn - False\n",
      "368 conv5_block3_1_relu - True\n",
      "369 conv5_block3_2_pad - True\n",
      "370 conv5_block3_2_conv - True\n",
      "371 conv5_block3_2_bn - False\n",
      "372 conv5_block3_2_relu - True\n",
      "373 conv5_block3_3_conv - True\n",
      "374 conv5_block3_out - True\n",
      "375 post_bn - False\n",
      "376 post_relu - True\n",
      "377 avg_pool - True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(resnet101.layers):\n",
    "    print(i, layer.name, \"-\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "repurposed.compile(optimizer=RMSprop(0.00001), loss=categorical_crossentropy, metrics=['accuracy', AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,204,551</span> (164.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,204,551\u001b[0m (164.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,214,215</span> (84.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,214,215\u001b[0m (84.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,990,336</span> (80.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,990,336\u001b[0m (80.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repurposed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.7281 - auc_2: 0.9453 - loss: 0.8052\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83071, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 1s/step - accuracy: 0.7281 - auc_2: 0.9453 - loss: 0.8052 - val_accuracy: 0.8307 - val_auc_2: 0.9763 - val_loss: 1.0752 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - accuracy: 0.7353 - auc_2: 0.9479 - loss: 0.7827\n",
      "Epoch 2: val_accuracy improved from 0.83071 to 0.85226, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 1s/step - accuracy: 0.7353 - auc_2: 0.9479 - loss: 0.7826 - val_accuracy: 0.8523 - val_auc_2: 0.9800 - val_loss: 0.9710 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - accuracy: 0.7405 - auc_2: 0.9506 - loss: 0.7629\n",
      "Epoch 3: val_accuracy did not improve from 0.85226\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 969ms/step - accuracy: 0.7406 - auc_2: 0.9506 - loss: 0.7628 - val_accuracy: 0.8440 - val_auc_2: 0.9788 - val_loss: 0.9337 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - accuracy: 0.7497 - auc_2: 0.9547 - loss: 0.7254\n",
      "Epoch 4: val_accuracy improved from 0.85226 to 0.86243, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 960ms/step - accuracy: 0.7497 - auc_2: 0.9547 - loss: 0.7253 - val_accuracy: 0.8624 - val_auc_2: 0.9827 - val_loss: 0.9264 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.7630 - auc_2: 0.9583 - loss: 0.6970\n",
      "Epoch 5: val_accuracy improved from 0.86243 to 0.87540, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 911ms/step - accuracy: 0.7630 - auc_2: 0.9583 - loss: 0.6970 - val_accuracy: 0.8754 - val_auc_2: 0.9843 - val_loss: 0.9082 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602ms/step - accuracy: 0.7690 - auc_2: 0.9608 - loss: 0.6741\n",
      "Epoch 6: val_accuracy improved from 0.87540 to 0.88776, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 921ms/step - accuracy: 0.7690 - auc_2: 0.9608 - loss: 0.6741 - val_accuracy: 0.8878 - val_auc_2: 0.9871 - val_loss: 0.5334 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.7829 - auc_2: 0.9640 - loss: 0.6468\n",
      "Epoch 7: val_accuracy did not improve from 0.88776\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 911ms/step - accuracy: 0.7830 - auc_2: 0.9640 - loss: 0.6467 - val_accuracy: 0.8733 - val_auc_2: 0.9845 - val_loss: 0.8181 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.7825 - auc_2: 0.9652 - loss: 0.6367\n",
      "Epoch 8: val_accuracy improved from 0.88776 to 0.89143, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 916ms/step - accuracy: 0.7825 - auc_2: 0.9652 - loss: 0.6366 - val_accuracy: 0.8914 - val_auc_2: 0.9873 - val_loss: 0.8336 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8007 - auc_2: 0.9691 - loss: 0.5967\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.89143 to 0.89844, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 931ms/step - accuracy: 0.8007 - auc_2: 0.9691 - loss: 0.5967 - val_accuracy: 0.8984 - val_auc_2: 0.9886 - val_loss: 0.8864 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.8121 - auc_2: 0.9731 - loss: 0.5594\n",
      "Epoch 10: val_accuracy improved from 0.89844 to 0.92332, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 932ms/step - accuracy: 0.8122 - auc_2: 0.9731 - loss: 0.5593 - val_accuracy: 0.9233 - val_auc_2: 0.9918 - val_loss: 0.8813 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - accuracy: 0.8259 - auc_2: 0.9770 - loss: 0.5199\n",
      "Epoch 11: val_accuracy improved from 0.92332 to 0.93036, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 927ms/step - accuracy: 0.8259 - auc_2: 0.9770 - loss: 0.5199 - val_accuracy: 0.9304 - val_auc_2: 0.9927 - val_loss: 0.9358 - learning_rate: 5.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.8298 - auc_2: 0.9769 - loss: 0.5178\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.93036 to 0.93456, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 923ms/step - accuracy: 0.8298 - auc_2: 0.9769 - loss: 0.5176 - val_accuracy: 0.9346 - val_auc_2: 0.9929 - val_loss: 0.5973 - learning_rate: 5.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.8447 - auc_2: 0.9805 - loss: 0.4794\n",
      "Epoch 13: val_accuracy improved from 0.93456 to 0.94265, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 912ms/step - accuracy: 0.8448 - auc_2: 0.9805 - loss: 0.4793 - val_accuracy: 0.9426 - val_auc_2: 0.9940 - val_loss: 0.6627 - learning_rate: 2.5000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.8479 - auc_2: 0.9822 - loss: 0.4590\n",
      "Epoch 14: val_accuracy improved from 0.94265 to 0.94528, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 924ms/step - accuracy: 0.8479 - auc_2: 0.9822 - loss: 0.4589 - val_accuracy: 0.9453 - val_auc_2: 0.9943 - val_loss: 0.7544 - learning_rate: 2.5000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.8551 - auc_2: 0.9832 - loss: 0.4485\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 15: val_accuracy improved from 0.94528 to 0.94695, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 928ms/step - accuracy: 0.8551 - auc_2: 0.9832 - loss: 0.4485 - val_accuracy: 0.9469 - val_auc_2: 0.9946 - val_loss: 0.7246 - learning_rate: 2.5000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.8632 - auc_2: 0.9839 - loss: 0.4365\n",
      "Epoch 16: val_accuracy improved from 0.94695 to 0.94924, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 923ms/step - accuracy: 0.8632 - auc_2: 0.9839 - loss: 0.4364 - val_accuracy: 0.9492 - val_auc_2: 0.9946 - val_loss: 0.6486 - learning_rate: 1.2500e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.8625 - auc_2: 0.9842 - loss: 0.4345\n",
      "Epoch 17: val_accuracy improved from 0.94924 to 0.95129, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 927ms/step - accuracy: 0.8625 - auc_2: 0.9842 - loss: 0.4344 - val_accuracy: 0.9513 - val_auc_2: 0.9949 - val_loss: 0.7598 - learning_rate: 1.2500e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.8642 - auc_2: 0.9847 - loss: 0.4285\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 18: val_accuracy improved from 0.95129 to 0.95267, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 925ms/step - accuracy: 0.8642 - auc_2: 0.9847 - loss: 0.4284 - val_accuracy: 0.9527 - val_auc_2: 0.9951 - val_loss: 0.7368 - learning_rate: 1.2500e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.8648 - auc_2: 0.9855 - loss: 0.4176\n",
      "Epoch 19: val_accuracy improved from 0.95267 to 0.95368, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 944ms/step - accuracy: 0.8648 - auc_2: 0.9855 - loss: 0.4175 - val_accuracy: 0.9537 - val_auc_2: 0.9951 - val_loss: 0.7462 - learning_rate: 6.2500e-07\n",
      "Epoch 20/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.8691 - auc_2: 0.9860 - loss: 0.4112\n",
      "Epoch 20: val_accuracy improved from 0.95368 to 0.95441, saving model to resnetfinedtunedv2.keras\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 922ms/step - accuracy: 0.8691 - auc_2: 0.9860 - loss: 0.4111 - val_accuracy: 0.9544 - val_auc_2: 0.9951 - val_loss: 0.7040 - learning_rate: 6.2500e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23b916a9b90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.50, min_lr = 1e-7)\n",
    "checkpoint = ModelCheckpoint(filepath='resnetfinedtunedv2.keras', save_best_only=True, verbose=1, monitor='val_accuracy', mode='max')\n",
    "\n",
    "repurposed.fit(new_train_ds, validation_data=new_val_ds, epochs=epochs, callbacks=[reduce, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
