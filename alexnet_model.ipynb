{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_height = 48\n",
    "img_width = 48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir_train = pathlib.Path('./images/images/train')\n",
    "data_dir_val = pathlib.Path('./images/images/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  label_mode='categorical',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  color_mode='grayscale'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_val,\n",
    "  image_size=(img_height, img_width),\n",
    "  label_mode='categorical',\n",
    "  batch_size=batch_size,\n",
    "  color_mode='grayscale'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, Rescaling, RandomZoom, RandomContrast\n",
    "\n",
    "rescaling = Sequential([\n",
    "    Rescaling(1./255),\n",
    "])\n",
    "\n",
    "preprocessing_seq = Sequential([\n",
    "    rescaling,\n",
    "    RandomFlip(),\n",
    "    RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_ds = train_ds.map(\n",
    "    lambda x, y: (preprocessing_seq(x, training=True), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_ds = val_ds.map(\n",
    "    lambda x, y: (rescaling(x), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\garga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, Dropout, Dense, Lambda, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.nn import local_response_normalization\n",
    "\n",
    "alexnet = Sequential([\n",
    "    Input(shape=(48, 48, 1)),\n",
    "    Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation='relu'),\n",
    "    Lambda(local_response_normalization),\n",
    "    MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "    Lambda(local_response_normalization),\n",
    "    MaxPool2D(pool_size=3, strides=2,  padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,441,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,679</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m11,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m614,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │       \u001b[38;5;34m885,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m884,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │     \u001b[38;5;34m9,441,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │        \u001b[38;5;34m28,679\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,977,671</span> (114.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,977,671\u001b[0m (114.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,976,455</span> (114.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,976,455\u001b[0m (114.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import AUC, CategoricalAccuracy\n",
    "\n",
    "alexnet.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', AUC(curve='ROC')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 322ms/step - accuracy: 0.2449 - auc: 0.6528 - loss: 1.8074 - val_accuracy: 0.2481 - val_auc: 0.6436 - val_loss: 1.8232 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.2465 - auc: 0.6652 - loss: 1.7927 - val_accuracy: 0.2699 - val_auc: 0.6761 - val_loss: 1.7805 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.2589 - auc: 0.6751 - loss: 1.7781 - val_accuracy: 0.1994 - val_auc: 0.6214 - val_loss: 1.8426 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.2715 - auc: 0.6836 - loss: 1.7629 - val_accuracy: 0.2968 - val_auc: 0.6993 - val_loss: 1.7786 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.2958 - auc: 0.6998 - loss: 1.7318 - val_accuracy: 0.2911 - val_auc: 0.6910 - val_loss: 1.7590 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.3067 - auc: 0.7090 - loss: 1.7110 - val_accuracy: 0.3166 - val_auc: 0.7175 - val_loss: 1.7022 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.3205 - auc: 0.7213 - loss: 1.6863 - val_accuracy: 0.3300 - val_auc: 0.7292 - val_loss: 1.7003 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.3273 - auc: 0.7273 - loss: 1.6694 - val_accuracy: 0.2116 - val_auc: 0.6365 - val_loss: 1.8484 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.3283 - auc: 0.7332 - loss: 1.6567 - val_accuracy: 0.3452 - val_auc: 0.7455 - val_loss: 1.6597 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 315ms/step - accuracy: 0.3368 - auc: 0.7381 - loss: 1.6472 - val_accuracy: 0.3067 - val_auc: 0.7146 - val_loss: 1.7738 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.3459 - auc: 0.7466 - loss: 1.6240 - val_accuracy: 0.3637 - val_auc: 0.7641 - val_loss: 1.5913 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.3643 - auc: 0.7574 - loss: 1.6016 - val_accuracy: 0.3590 - val_auc: 0.7510 - val_loss: 1.6429 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.3693 - auc: 0.7618 - loss: 1.5930 - val_accuracy: 0.3671 - val_auc: 0.7620 - val_loss: 1.6031 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.3717 - auc: 0.7661 - loss: 1.5793 - val_accuracy: 0.3725 - val_auc: 0.7589 - val_loss: 1.6001 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.3822 - auc: 0.7748 - loss: 1.5556 - val_accuracy: 0.4053 - val_auc: 0.7840 - val_loss: 1.5326 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.3845 - auc: 0.7770 - loss: 1.5504 - val_accuracy: 0.3801 - val_auc: 0.7663 - val_loss: 1.5865 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.4030 - auc: 0.7843 - loss: 1.5319 - val_accuracy: 0.3924 - val_auc: 0.7763 - val_loss: 1.5524 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.3995 - auc: 0.7843 - loss: 1.5317 - val_accuracy: 0.3943 - val_auc: 0.7824 - val_loss: 1.5509 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.3916 - auc: 0.7824 - loss: 1.5369 - val_accuracy: 0.4261 - val_auc: 0.7979 - val_loss: 1.4905 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 318ms/step - accuracy: 0.4125 - auc: 0.7941 - loss: 1.5026 - val_accuracy: 0.4291 - val_auc: 0.8027 - val_loss: 1.4751 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4126 - auc: 0.7948 - loss: 1.4992 - val_accuracy: 0.4113 - val_auc: 0.7920 - val_loss: 1.5059 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.4135 - auc: 0.7970 - loss: 1.4934 - val_accuracy: 0.3913 - val_auc: 0.7739 - val_loss: 1.6147 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4166 - auc: 0.7985 - loss: 1.4901 - val_accuracy: 0.4001 - val_auc: 0.7837 - val_loss: 1.5339 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.4223 - auc: 0.8013 - loss: 1.4795\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4223 - auc: 0.8013 - loss: 1.4795 - val_accuracy: 0.3798 - val_auc: 0.7693 - val_loss: 1.5748 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 331ms/step - accuracy: 0.4348 - auc: 0.8103 - loss: 1.4492 - val_accuracy: 0.4441 - val_auc: 0.8150 - val_loss: 1.4352 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4340 - auc: 0.8128 - loss: 1.4381 - val_accuracy: 0.4341 - val_auc: 0.8141 - val_loss: 1.4330 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 315ms/step - accuracy: 0.4417 - auc: 0.8203 - loss: 1.4168 - val_accuracy: 0.3963 - val_auc: 0.7802 - val_loss: 1.5631 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.4442 - auc: 0.8204 - loss: 1.4146 - val_accuracy: 0.4302 - val_auc: 0.8072 - val_loss: 1.4674 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 318ms/step - accuracy: 0.4505 - auc: 0.8233 - loss: 1.4054 - val_accuracy: 0.4454 - val_auc: 0.8174 - val_loss: 1.4256 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4571 - auc: 0.8256 - loss: 1.3987 - val_accuracy: 0.4196 - val_auc: 0.7973 - val_loss: 1.5404 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4576 - auc: 0.8277 - loss: 1.3905 - val_accuracy: 0.4355 - val_auc: 0.8066 - val_loss: 1.4671 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 318ms/step - accuracy: 0.4596 - auc: 0.8271 - loss: 1.3928 - val_accuracy: 0.4601 - val_auc: 0.8268 - val_loss: 1.4146 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4623 - auc: 0.8293 - loss: 1.3836 - val_accuracy: 0.4229 - val_auc: 0.7995 - val_loss: 1.4931 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4632 - auc: 0.8316 - loss: 1.3768 - val_accuracy: 0.4643 - val_auc: 0.8268 - val_loss: 1.4198 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 321ms/step - accuracy: 0.4655 - auc: 0.8327 - loss: 1.3697 - val_accuracy: 0.4601 - val_auc: 0.8255 - val_loss: 1.4069 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.4681 - auc: 0.8336 - loss: 1.3698 - val_accuracy: 0.4614 - val_auc: 0.8282 - val_loss: 1.3947 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 313ms/step - accuracy: 0.4729 - auc: 0.8372 - loss: 1.3565 - val_accuracy: 0.4636 - val_auc: 0.8298 - val_loss: 1.3895 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 311ms/step - accuracy: 0.4721 - auc: 0.8370 - loss: 1.3550 - val_accuracy: 0.4635 - val_auc: 0.8306 - val_loss: 1.3838 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.4795 - auc: 0.8388 - loss: 1.3511 - val_accuracy: 0.4734 - val_auc: 0.8343 - val_loss: 1.3756 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.4786 - auc: 0.8411 - loss: 1.3422 - val_accuracy: 0.4421 - val_auc: 0.8147 - val_loss: 1.4489 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 313ms/step - accuracy: 0.4807 - auc: 0.8394 - loss: 1.3492 - val_accuracy: 0.4782 - val_auc: 0.8377 - val_loss: 1.3651 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.4831 - auc: 0.8431 - loss: 1.3364 - val_accuracy: 0.4826 - val_auc: 0.8361 - val_loss: 1.3656 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.4831 - auc: 0.8438 - loss: 1.3317 - val_accuracy: 0.4744 - val_auc: 0.8353 - val_loss: 1.4115 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 313ms/step - accuracy: 0.4887 - auc: 0.8451 - loss: 1.3273 - val_accuracy: 0.4686 - val_auc: 0.8303 - val_loss: 1.3971 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 315ms/step - accuracy: 0.4911 - auc: 0.8468 - loss: 1.3219 - val_accuracy: 0.4775 - val_auc: 0.8368 - val_loss: 1.3639 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.4948 - auc: 0.8481 - loss: 1.3167 - val_accuracy: 0.4672 - val_auc: 0.8329 - val_loss: 1.3823 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 327ms/step - accuracy: 0.4957 - auc: 0.8500 - loss: 1.3076 - val_accuracy: 0.4863 - val_auc: 0.8434 - val_loss: 1.3381 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.4986 - auc: 0.8529 - loss: 1.2977 - val_accuracy: 0.4759 - val_auc: 0.8351 - val_loss: 1.3753 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.5067 - auc: 0.8536 - loss: 1.2953 - val_accuracy: 0.4798 - val_auc: 0.8379 - val_loss: 1.3585 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 314ms/step - accuracy: 0.5051 - auc: 0.8536 - loss: 1.2965 - val_accuracy: 0.4316 - val_auc: 0.8083 - val_loss: 1.4756 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.5045 - auc: 0.8556 - loss: 1.2876\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 316ms/step - accuracy: 0.5045 - auc: 0.8556 - loss: 1.2875 - val_accuracy: 0.4868 - val_auc: 0.8427 - val_loss: 1.3588 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.5138 - auc: 0.8596 - loss: 1.2715 - val_accuracy: 0.4921 - val_auc: 0.8488 - val_loss: 1.3193 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 317ms/step - accuracy: 0.5227 - auc: 0.8636 - loss: 1.2544 - val_accuracy: 0.5017 - val_auc: 0.8547 - val_loss: 1.2937 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 328ms/step - accuracy: 0.5203 - auc: 0.8647 - loss: 1.2489 - val_accuracy: 0.4948 - val_auc: 0.8538 - val_loss: 1.2993 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 331ms/step - accuracy: 0.5266 - auc: 0.8674 - loss: 1.2383 - val_accuracy: 0.5033 - val_auc: 0.8546 - val_loss: 1.3082 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 312ms/step - accuracy: 0.5293 - auc: 0.8687 - loss: 1.2307 - val_accuracy: 0.4942 - val_auc: 0.8473 - val_loss: 1.3259 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.5302 - auc: 0.8692 - loss: 1.2299\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 311ms/step - accuracy: 0.5302 - auc: 0.8692 - loss: 1.2299 - val_accuracy: 0.5027 - val_auc: 0.8561 - val_loss: 1.2981 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5336 - auc: 0.8695 - loss: 1.2292 - val_accuracy: 0.5119 - val_auc: 0.8597 - val_loss: 1.2827 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.5398 - auc: 0.8724 - loss: 1.2154 - val_accuracy: 0.5099 - val_auc: 0.8605 - val_loss: 1.2775 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 334ms/step - accuracy: 0.5396 - auc: 0.8735 - loss: 1.2114 - val_accuracy: 0.5034 - val_auc: 0.8582 - val_loss: 1.2807 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 334ms/step - accuracy: 0.5428 - auc: 0.8753 - loss: 1.2039 - val_accuracy: 0.5113 - val_auc: 0.8600 - val_loss: 1.2760 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 341ms/step - accuracy: 0.5455 - auc: 0.8768 - loss: 1.1958 - val_accuracy: 0.5068 - val_auc: 0.8583 - val_loss: 1.2822 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 332ms/step - accuracy: 0.5400 - auc: 0.8758 - loss: 1.1998 - val_accuracy: 0.5085 - val_auc: 0.8588 - val_loss: 1.2838 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 346ms/step - accuracy: 0.5429 - auc: 0.8779 - loss: 1.1920 - val_accuracy: 0.5127 - val_auc: 0.8602 - val_loss: 1.2759 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 340ms/step - accuracy: 0.5455 - auc: 0.8770 - loss: 1.1951 - val_accuracy: 0.4975 - val_auc: 0.8468 - val_loss: 1.3402 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 338ms/step - accuracy: 0.5473 - auc: 0.8793 - loss: 1.1856 - val_accuracy: 0.5055 - val_auc: 0.8584 - val_loss: 1.2867 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 333ms/step - accuracy: 0.5503 - auc: 0.8790 - loss: 1.1872 - val_accuracy: 0.5078 - val_auc: 0.8610 - val_loss: 1.2702 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 354ms/step - accuracy: 0.5501 - auc: 0.8811 - loss: 1.1757 - val_accuracy: 0.5106 - val_auc: 0.8616 - val_loss: 1.2715 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 347ms/step - accuracy: 0.5508 - auc: 0.8815 - loss: 1.1749 - val_accuracy: 0.5137 - val_auc: 0.8616 - val_loss: 1.2739 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 338ms/step - accuracy: 0.5574 - auc: 0.8818 - loss: 1.1731 - val_accuracy: 0.5089 - val_auc: 0.8603 - val_loss: 1.2765 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.5529 - auc: 0.8811 - loss: 1.1765\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.5529 - auc: 0.8811 - loss: 1.1764 - val_accuracy: 0.5143 - val_auc: 0.8621 - val_loss: 1.2724 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 320ms/step - accuracy: 0.5510 - auc: 0.8827 - loss: 1.1692 - val_accuracy: 0.5142 - val_auc: 0.8643 - val_loss: 1.2600 - learning_rate: 6.2500e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.5548 - auc: 0.8845 - loss: 1.1602 - val_accuracy: 0.5105 - val_auc: 0.8602 - val_loss: 1.2752 - learning_rate: 6.2500e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 345ms/step - accuracy: 0.5613 - auc: 0.8861 - loss: 1.1525 - val_accuracy: 0.5149 - val_auc: 0.8637 - val_loss: 1.2649 - learning_rate: 6.2500e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5619 - auc: 0.8858 - loss: 1.1548 - val_accuracy: 0.5134 - val_auc: 0.8632 - val_loss: 1.2640 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 344ms/step - accuracy: 0.5649 - auc: 0.8857 - loss: 1.1557 - val_accuracy: 0.5168 - val_auc: 0.8656 - val_loss: 1.2592 - learning_rate: 6.2500e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 342ms/step - accuracy: 0.5608 - auc: 0.8854 - loss: 1.1553 - val_accuracy: 0.5156 - val_auc: 0.8632 - val_loss: 1.2632 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5673 - auc: 0.8869 - loss: 1.1488 - val_accuracy: 0.5190 - val_auc: 0.8639 - val_loss: 1.2625 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 338ms/step - accuracy: 0.5656 - auc: 0.8870 - loss: 1.1487 - val_accuracy: 0.5168 - val_auc: 0.8643 - val_loss: 1.2623 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 344ms/step - accuracy: 0.5600 - auc: 0.8863 - loss: 1.1535 - val_accuracy: 0.5190 - val_auc: 0.8659 - val_loss: 1.2581 - learning_rate: 6.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 344ms/step - accuracy: 0.5656 - auc: 0.8876 - loss: 1.1461 - val_accuracy: 0.5208 - val_auc: 0.8659 - val_loss: 1.2564 - learning_rate: 6.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 347ms/step - accuracy: 0.5668 - auc: 0.8883 - loss: 1.1421 - val_accuracy: 0.5183 - val_auc: 0.8647 - val_loss: 1.2673 - learning_rate: 6.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 345ms/step - accuracy: 0.5691 - auc: 0.8881 - loss: 1.1428 - val_accuracy: 0.5183 - val_auc: 0.8633 - val_loss: 1.2728 - learning_rate: 6.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 338ms/step - accuracy: 0.5678 - auc: 0.8888 - loss: 1.1400 - val_accuracy: 0.5132 - val_auc: 0.8641 - val_loss: 1.2675 - learning_rate: 6.2500e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.5667 - auc: 0.8893 - loss: 1.1378\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 343ms/step - accuracy: 0.5667 - auc: 0.8893 - loss: 1.1378 - val_accuracy: 0.5202 - val_auc: 0.8650 - val_loss: 1.2601 - learning_rate: 6.2500e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5677 - auc: 0.8897 - loss: 1.1360 - val_accuracy: 0.5177 - val_auc: 0.8660 - val_loss: 1.2577 - learning_rate: 3.1250e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5681 - auc: 0.8892 - loss: 1.1385 - val_accuracy: 0.5204 - val_auc: 0.8650 - val_loss: 1.2633 - learning_rate: 3.1250e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.5696 - auc: 0.8894 - loss: 1.1368 - val_accuracy: 0.5218 - val_auc: 0.8666 - val_loss: 1.2568 - learning_rate: 3.1250e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.5720 - auc: 0.8905 - loss: 1.1324\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 340ms/step - accuracy: 0.5720 - auc: 0.8905 - loss: 1.1324 - val_accuracy: 0.5212 - val_auc: 0.8646 - val_loss: 1.2646 - learning_rate: 3.1250e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 345ms/step - accuracy: 0.5696 - auc: 0.8914 - loss: 1.1264 - val_accuracy: 0.5224 - val_auc: 0.8660 - val_loss: 1.2601 - learning_rate: 1.5625e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 349ms/step - accuracy: 0.5727 - auc: 0.8914 - loss: 1.1280 - val_accuracy: 0.5222 - val_auc: 0.8658 - val_loss: 1.2599 - learning_rate: 1.5625e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 344ms/step - accuracy: 0.5692 - auc: 0.8900 - loss: 1.1334 - val_accuracy: 0.5221 - val_auc: 0.8662 - val_loss: 1.2589 - learning_rate: 1.5625e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.5746 - auc: 0.8921 - loss: 1.1247\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 342ms/step - accuracy: 0.5746 - auc: 0.8921 - loss: 1.1247 - val_accuracy: 0.5221 - val_auc: 0.8660 - val_loss: 1.2595 - learning_rate: 1.5625e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 349ms/step - accuracy: 0.5726 - auc: 0.8919 - loss: 1.1255 - val_accuracy: 0.5218 - val_auc: 0.8656 - val_loss: 1.2625 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 351ms/step - accuracy: 0.5743 - auc: 0.8924 - loss: 1.1221 - val_accuracy: 0.5236 - val_auc: 0.8662 - val_loss: 1.2602 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 339ms/step - accuracy: 0.5737 - auc: 0.8929 - loss: 1.1199 - val_accuracy: 0.5229 - val_auc: 0.8657 - val_loss: 1.2629 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 347ms/step - accuracy: 0.5720 - auc: 0.8918 - loss: 1.1248 - val_accuracy: 0.5253 - val_auc: 0.8663 - val_loss: 1.2619 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 354ms/step - accuracy: 0.5729 - auc: 0.8925 - loss: 1.1224 - val_accuracy: 0.5209 - val_auc: 0.8659 - val_loss: 1.2621 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 342ms/step - accuracy: 0.5714 - auc: 0.8928 - loss: 1.1203 - val_accuracy: 0.5224 - val_auc: 0.8656 - val_loss: 1.2634 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 354ms/step - accuracy: 0.5773 - auc: 0.8938 - loss: 1.1152 - val_accuracy: 0.5202 - val_auc: 0.8645 - val_loss: 1.2688 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a4df165c50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor = 'val_loss', patience = 4, verbose = 1, factor = 0.50, min_lr = 1e-5)\n",
    "checkpoint = ModelCheckpoint('./weights/alexnet.weights.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=True, mode='max')\n",
    "\n",
    "\n",
    "alexnet.fit(\n",
    "    new_train_ds, \n",
    "    validation_data=new_val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, reduce]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential([\n",
    "    Input(shape=(48, 48, 1)),\n",
    "    Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation='relu'),\n",
    "    Lambda(local_response_normalization),\n",
    "    MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "    Lambda(local_response_normalization),\n",
    "    MaxPool2D(pool_size=3, strides=2,  padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.load_weights('./weights/alexnet.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.asarray(Image.open('./images/validation/angry/842.jpg'))\n",
    "img = img[np.newaxis, :, :, np.newaxis]\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = new_model.predict(img)\n",
    "np.argmax(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
